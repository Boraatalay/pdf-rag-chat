from langchain_community.llms import Ollama
from langchain.callbacks.manager import CallbackManager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.chains import ConversationalRetrievalChain
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferWindowMemory

class RAGChain:
    def __init__(self, vectorstore, model_name: str, base_url: str, temperature: float = 0.1):
        self.vectorstore = vectorstore
        
        # Memory ekleme - son 5 konuÅŸmayÄ± hatÄ±rlar
        self.memory = ConversationBufferWindowMemory(
            k=5,  # Son 5 soru-cevap Ã§iftini hatÄ±rla
            memory_key="chat_history",
            return_messages=True,
            output_key="answer"
        )
        
# Temperature aralÄ±klarÄ±na gÃ¶re prompt seÃ§imi
        if temperature >= 1.5:
    # Ultra YaratÄ±cÄ± Mode (1.5-2.0)
            self.prompt_template = """Sen sÄ±radÄ±ÅŸÄ± zekaya sahip, yaratÄ±cÄ± ve vizyoner bir PDF analiz sanatÃ§Ä±sÄ±sÄ±n! ğŸ¨âœ¨

â“ KullanÄ±cÄ±nÄ±n bÃ¼yÃ¼leyici sorusu: "{question}"

ğŸ“„ PDF'teki gizli hazineler:
{context}

ğŸš€ ULTRA YARATICI MOD!
- PDF'i sanki bir sanat eseri gibi yorumla
- SÄ±radÄ±ÅŸÄ± metaforlar ve benzetmeler kullan  
- FarklÄ± disiplinlerden Ã¶rnekler getir
- Felsefi derinlik kat
- Ä°maginatif senaryolar Ã¼ret
- PDF iÃ§eriÄŸindeki sembolleri keÅŸfet
- Alternatif gerÃ§eklikler sun

ğŸ’ SANATSAL YAKLAÅIM:
- Her cevabÄ± bir hikaye gibi anlat
- Duygusal baÄŸlar kur
- Renkli betimlemeler kullan
- PDF'teki verileri yaÅŸayan karakterler gibi gÃ¶r

ğŸ’¬ Ã–nceki bÃ¼yÃ¼lÃ¼ konuÅŸmalar: {chat_history}

ğŸŒŸ Ultra yaratÄ±cÄ± ÅŸaheserini sun:"""

        elif temperature >= 1.0:
    # YaratÄ±cÄ± Mode (1.0-1.5)
            self.prompt_template = """Sen yaratÄ±cÄ±, analitik ve ilham verici bir PDF uzmanÄ±sÄ±n! ğŸ¯

â“ KullanÄ±cÄ±nÄ±n sorusu: "{question}"

ğŸ“„ PDF'in zengin iÃ§eriÄŸi:
{context}

ğŸ¨ YARATICI MOD AKTIF!
- PDF bilgilerini yaratÄ±cÄ± aÃ§Ä±lardan ele al
- Ä°lginÃ§ baÄŸlantÄ±lar ve kalÄ±plar keÅŸfet
- FarklÄ± bakÄ±ÅŸ aÃ§Ä±larÄ± sun
- YaratÄ±cÄ± Ã¶rnekler ve metaforlar kullan
- PDF iÃ§eriÄŸindeki derin anlamlarÄ± ortaya Ã§Ä±kar
- EleÅŸtirel dÃ¼ÅŸÃ¼nme uygula

ğŸ”¥ YARATICI YAKLIÅIM:
- Analitik + intuitif dÃ¼ÅŸÃ¼nce birleÅŸtir
- KonularÄ± birbirine baÄŸla
- Ã–ngÃ¶rÃ¼lÃ¼ yorumlar yap
- PDF'teki gizli mesajlarÄ± bul

ğŸ’¬ Ã–nceki yaratÄ±cÄ± konuÅŸmalar: {chat_history}

âœ¨ YaratÄ±cÄ± ve derinlikli cevabÄ±n:"""

        elif temperature >= 0.5:
    # Dengeli Mode (0.5-1.0)
            self.prompt_template = """Sen deneyimli ve dengeli bir PDF analiz uzmanÄ±sÄ±n.

â“ KullanÄ±cÄ±nÄ±n sorusu: "{question}"

ğŸ“„ PDF BaÄŸlamÄ±:
{context}

ğŸ¯ DENGELI YAKLAÅIM:
- PDF iÃ§eriÄŸini hem objektif hem Ã¶znel deÄŸerlendir
- GerektiÄŸinde yorumlayÄ±cÄ± ol
- FarklÄ± perspektifleri gÃ¶z Ã¶nÃ¼nde bulundur
- BaÄŸlamsal Ã§Ä±karÄ±mlar yap
- PDF verilerini analitik ÅŸekilde sun

ğŸ“Š AKILLI ANALÄ°Z:
- Ã–ncelikle doÄŸrudan cevaplarÄ± ver
- Sonra ek analizler ekle  
- Ã‡Ä±karÄ±mlarda bulun
- PDF'teki kalÄ±plarÄ± tanÄ±mla

ğŸ’¬ Ã–nceki konuÅŸma: {chat_history}

ğŸ“Œ Dengeli ve analitik cevabÄ±n:"""

        else:
    # TutarlÄ± Mode (0.0-0.5)
            self.prompt_template = """AÅŸaÄŸÄ±da verilen baÄŸlam, bir PDF belgesinden alÄ±nmÄ±ÅŸtÄ±r.
Ã–nceki konuÅŸma geÃ§miÅŸini de dikkate alarak kullanÄ±cÄ±nÄ±n sorusunu yanÄ±tla.

âš ï¸ UyarÄ±lar:
- Ã–ncelikle PDF baÄŸlamÄ±ndaki bilgileri kullan
- Ã–nceki konuÅŸmalarda geÃ§en bilgilere referans verebilirsin
- Sadece baÄŸlamda geÃ§en ifadeleri kullan
- Cevap bulamazsan, "Bu sorunun cevabÄ± PDF iÃ§eriÄŸinde aÃ§Ä±kÃ§a belirtilmemiÅŸ." yaz

---

ğŸ“„ PDF BaÄŸlamÄ±:
{context}

ğŸ’¬ Ã–nceki KonuÅŸma:
{chat_history}

â“ Soru:
{question}

---

ğŸ“Œ Cevap:
"""
        
        self.PROMPT = PromptTemplate(
            template=self.prompt_template,
            input_variables=["context", "chat_history", "question"]
        )
        
        # Ollama LLM - temperature parametresi eklendi
        self.llm = Ollama(
            model=model_name,
            base_url=base_url,
            callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),
            temperature=temperature  # Temperature parametresi eklendi
        )
        
        # ConversationalRetrievalChain kullan
        self.qa_chain = ConversationalRetrievalChain.from_llm(
            llm=self.llm,
            retriever=self.vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 15}
            ),
            memory=self.memory,
            return_source_documents=True,
            combine_docs_chain_kwargs={"prompt": self.PROMPT},
            verbose=False
        )
    
    def query(self, question: str) -> dict:
        """Soruyu yanÄ±tla ve kaynak belgeleri dÃ¶ndÃ¼r - Memory ile"""
        
        # Basit anahtar kelime kontrolÃ¼ ekle
        pdf_unrelated_keywords = ['mutluluk', 'Ã¼zÃ¼ntÃ¼', 'kod yaz', 'program', 'python', 'javascript', 'matematik', 'hesapla', 'hava durumu', 'ne haber', 'nasÄ±lsÄ±n', 'merhaba', 'selam']
        
        question_lower = question.lower()
        if any(keyword in question_lower for keyword in pdf_unrelated_keywords):
            return {
                "answer": "Bu soru PDF iÃ§eriklerim ile ilgili deÄŸil. LÃ¼tfen yÃ¼klediÄŸiniz PDF belgeleri hakkÄ±nda soru sorun.",
                "source_documents": []
            }
        
        result = self.qa_chain.invoke({"question": question})
        return {
            "answer": result["answer"],
            "source_documents": result["source_documents"]
        }
    
    def clear_memory(self):
        """KonuÅŸma geÃ§miÅŸini temizle"""
        self.memory.clear()
    
    def get_memory_summary(self):
        """Memory durumu hakkÄ±nda bilgi dÃ¶ndÃ¼r"""
        try:
            message_count = len(self.memory.chat_memory.messages)
            return f"HafÄ±zada {message_count//2} konuÅŸma var"
        except:
            return "Memory durumu alÄ±namadÄ±"